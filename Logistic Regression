from scipy import stats
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
X1=np.array([1,3,5,7,9,11,13,15,17,19])
Y1=np.array([1,1,1,1,1,1,1,1,1,1])
X2=np.array([2,4,6,8,10,12,14,16,18,20])
Y2=np.array([0,0,0,0,0,0,0,0,0,0])
X=np.array([[1],[3],[5],[7],[9],[11],[13],[15],[17],[19],[2],[4],[6],[8],[10],[12],[14],[16],[18],[20]])
Y=np.array([1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0])
plt.plot(X1,Y1,'ro',color='blue')
plt.plot(X2,Y2,'ro',color='black')
plt.axis([0,30,-0.5,2])
plt.show()
classifier=LogisticRegression()
classifier.fit(X,Y) #this will find the best logistic paremter a,b
prediction=classifier.predict_proba(22) #print prob  while this prediction=classifier.predict(22) print class
print("built in prediction",prediction)

# i noticed that logistic regression will never solve the odd-even problem .. he biased to the even as the even numbers are larger than odd ones 22>19.

# we can return the prob if we access the a and b after fitting the classifier.
def RegMod(classifier,x):
    P=1 / (1 + np.exp(-(classifier.intercept_ + classifier.coef_ * x))) #P(x)=1/1+exp(- (ax+b))
    R=[1-P,P]
    return R
pred=RegMod(classifier,22)
print("manual prediction",pred)

#Multivariate logistic regression (more than 1 feature)
#balance income age. can pay back the loan?? 0/1
X=np.array([[10000,800000,35],[7000,1200000,57],[100,23000,22],[220,18000,26]]) #2D
Y=np.array([1,1,0,0])
BankClassifier=LogisticRegression()
BankClassifier.fit(X,Y)
P=BankClassifier.predict([[500,50000,23]]) #2D
print(P)
'''
#when reading a CSV file using pandas we can use data.decribe() will return info about the dataset(max,count,avg,standard div,..)
#Xtrain Xtest Ytrain Ytest = train_test_split(data,targets,test_size=0.2) each fold=20% in cross validation
#confusion_matrix(targets,predictions)
#accuracy_score(targets,predictions)
# classifier= KNeighborsClassifier(n_neighbours=3)
